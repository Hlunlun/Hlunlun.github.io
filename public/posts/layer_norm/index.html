<!DOCTYPE html>
<html
  lang="en-us"
  prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#"
>
  



  
  


<head lang="en-us"><script src="/Hlunlun/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=Hlunlun/livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="color-scheme" content="dark light">
  <meta name="description" content="為什麼Transformer要用Layer Normalization" />
  <meta name="author" content="Lun">
  <meta name="keywords" content="normalization, layer_norm">
  <title>Layer Normalization VS. Batch Normalization | Lun&#39;s</title>
  <link rel="canonical" href="http://localhost:1313/Hlunlun/posts/layer_norm/" />
  

  
  <meta property="og:type" content="article" />
  <meta property="og:description" content="為什麼Transformer要用Layer Normalization" />
  <meta property="og:title" content="Layer Normalization VS. Batch Normalization" />
  <meta property="og:site_name" content="Lun&#39;s" />
  <meta property="og:image:type" content="image/jpeg" />
  <meta property="og:url" content="http://localhost:1313/Hlunlun/posts/layer_norm/" />
  <meta property="og:locale" content="en-us" />

  
    <meta property="article:published_time" content="2024-12-10" />
    <meta property="article:modified_time" content="2024-12-10" />
     
      <meta property="article:tag" content="normalization" />
    
      <meta property="article:tag" content="layer_norm" />
     
  

  
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Layer Normalization VS. Batch Normalization | Lun&#39;s" />
  <meta name="twitter:description" content="為什麼Transformer要用Layer Normalization" />
  <meta name="twitter:domain" content="http://localhost:1313/Hlunlun/posts/layer_norm/" />

  
  
    <link rel="icon" href="http://localhost:1313/Hlunlun/favicon.ico">
  
  
  
  

  
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/modern-normalize/modern-normalize.min.css">

  
  
  

  

  
    <link rel="stylesheet" href="http://localhost:1313/Hlunlun/style.css" rel="preload stylesheet" as="style"/>
  

  
  
</head>

  <body>
    <header id="header">
  <div class="row">
    <div class="container has-padding nav">
      <button id="navbar-toggler" class="navbar-button" aria-hidden="true">











<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M64 384h384v-42.67H64zm0-106.67h384v-42.66H64zM64 128v42.67h384V128z'/></svg>





</button>
      <div class="navbar-brand">
        <a class="logo navbar-button" href="http://localhost:1313/Hlunlun/" title="Lun&#39;s">
          <span>Lun&#39;s</span>
        </a>
      </div>
      <nav class="navbar" role="navigation">
        <ul>
          
          
            <li class="nav-bar-item active">
              <a class="nav-link navbar-button" href="/Hlunlun/posts/" title="posts">
                <span>posts</span>
              </a>
            </li>
          
            <li class="nav-bar-item">
              <a class="nav-link navbar-button" href="/Hlunlun/tags/" title="tags">
                <span>tags</span>
              </a>
            </li>
          
            <li class="nav-bar-item">
              <a class="nav-link navbar-button" href="/Hlunlun/archives/" title="archives">
                <span>archives</span>
              </a>
            </li>
          
            <li class="nav-bar-item">
              <a class="nav-link navbar-button" href="/Hlunlun/about/" title="about">
                <span>about</span>
              </a>
            </li>
          
        </ul>
      </nav>
      <div class="theme-selector">
        <button class="button is-text" id="theme-selector-button" title="toggle theme">
          <span class="label icon">





<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M256 32C132.29 32 32 132.29 32 256s100.29 224 224 224 224-100.29 224-224S379.71 32 256 32zM128.72 383.28A180 180 0 01256 76v360a178.82 178.82 0 01-127.28-52.72z'/></svg>











</span>
        </button>
      </div>
    </div>
    
      <div class="container has-padding">
        <div class="breadcrumb">
          
<ol  class="breadcrumb-nav">
  

  

  

<li >
  <a href="http://localhost:1313/Hlunlun/">Home</a>
</li>


<li >
  <a href="http://localhost:1313/Hlunlun/posts/">Posts</a>
</li>


<li class="active">
  <a href="http://localhost:1313/Hlunlun/posts/layer_norm/">Layer Normalization VS. Batch Normalization</a>
</li>

</ol>




        </div>
      </div>
    
  </div>
</header>

    

<main id="main">
  <div class="container has-padding">
    <div class="article-card post single">
      <h1 class="title">Layer Normalization VS. Batch Normalization</h1>
      <div class="post-info">
        <span>



<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M32 456a24 24 0 0024 24h400a24 24 0 0024-24V176H32zm320-244a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zM456 64h-55.92V32h-48v32H159.92V32h-48v32H56a23.8 23.8 0 00-24 23.77V144h448V87.77A23.8 23.8 0 00456 64z'/></svg>













<time datetime=2024-12-10T23:38:26&#43;0800 class="date">December 10, 2024</time></span>
        <span>
















<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M256 48C141.13 48 48 141.13 48 256c0 114.69 93.32 208 208 208 114.86 0 208-93.14 208-208 0-114.69-93.31-208-208-208zm108 240H244a4 4 0 01-4-4V116a4 4 0 014-4h24a4 4 0 014 4v140h92a4 4 0 014 4v24a4 4 0 01-4 4z'/></svg>
a min to read</span>
        
          <span>












<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M256 256a112 112 0 10-112-112 112 112 0 00112 112zm0 32c-69.42 0-208 42.88-208 128v64h416v-64c0-85.12-138.58-128-208-128z'/></svg>




Lun</span>
        
        
        
          <span>posts </span>
        
      </div>
      <article class="post-entry content">
        
          <img src="ln_bn_0.png" width =500 style=" margin: auto; display: block;">
<p>通過上圖可以很明顯看出，BN就是把多個layer後正規化，而LN是把單一個layer的正規化</p>
<table>
<thead>
<tr>
<th>H</th>
<th>C</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>The number of hidden units in a layer</td>
<td>channel(指feauture的維度，像是圖片的pixel有RGB那就是3個channel)</td>
<td>Batch size</td>
</tr>
</tbody>
</table>
<h2 id="所以為什麼要batch-normalization">所以為什麼要Batch Normalization?<a hidden class="heading-anchor" aria-hidden="true" href="#所以為什麼要batch-normalization">#</a></h2>
<ul>
<li>出自<a href="https://arxiv.org/pdf/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li>
</ul>
<h3 id="不適合序列模型">不適合序列模型<a hidden class="heading-anchor" aria-hidden="true" href="#不適合序列模型">#</a></h3>
<ul>
<li>想像現在有四個句子
<pre tabindex="0"><code>我是成大資工系的學生
他在英國倫敦的公司上班
星際效應要重映了
批次正規化是一種防止梯度爆炸的方法
</code></pre></li>
<li>如果用BN對上述句子做正規化
<ul>
<li>依照BN做法: 我們會選出不同資料中同位置的字，假設選取位置為0的字
<pre tabindex="0"><code>我...
他...
星...
批...
</code></pre></li>
<li>所以呢?這是在幹嘛?即使是同一個位置但語境不同，他們完全沒有相關之處，遑論要將他們&quot;正規化&quot;</li>
</ul>
</li>
<li>應該是在他們的語境中正規化，量化一個句子並正規化其中的token</li>
</ul>
<h2 id="所以為什麼要layer-normalization">所以為什麼要Layer Normalization?<a hidden class="heading-anchor" aria-hidden="true" href="#所以為什麼要layer-normalization">#</a></h2>
<h3 id="論文">論文<a hidden class="heading-anchor" aria-hidden="true" href="#論文">#</a></h3>
<p>出自2016的這篇論文: <a href="https://arxiv.org/pdf/1607.06450">Layer Normalization</a></p>
<h3 id="數學意義">數學意義<a hidden class="heading-anchor" aria-hidden="true" href="#數學意義">#</a></h3>
<p>先從數學上來說LN，其實也是正規化會遇到的數學算式，我們要先找到平均值，這個平均值是用整個layer \(l\) 的所有 \(H\) 個 hidden unit \(a^l_i\) 算出來的，標準差就是用剛剛算的平均值再倒入算式即可得出</p>
<img src="layer_norm.png" style=" margin: auto; display: block;">
<h3 id="適合序列模型">適合序列模型<a hidden class="heading-anchor" aria-hidden="true" href="#適合序列模型">#</a></h3>
<p>所以這裡的最小單位是hidden unit \(a^l_i\)，所有值都是在一個layer中，跟BN看的角度相比就比較微觀，畢竟BN是多個layer後在正規化，但是LN正好對RNN、LSTM、Transformer等這種序列模型非常加分，為何?</p>
<ul>
<li>可以先參考<a href="https://blog.csdn.net/jq_98/article/details/123300010">這張圖</a></li>
<li>
<p>因為對於RNN來說，用BN來學習平均值和標準差是很難的，所以用LN的方式讓序列模型可以在自己所處的context(上下文)中學習 \(\mu\) 和 \(std\) 是比較容易的，所以LN是對序列模型來說最佳的正規化方法</p>
</li>
</ul>
<h3 id="程式碼的呈現">程式碼的呈現<a hidden class="heading-anchor" aria-hidden="true" href="#程式碼的呈現">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;Construct a layernorm module (See citation for details).&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">a_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">b_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">a_2</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_2</span>
</span></span></code></pre></div><ul>
<li>
<p>這邊要解釋一下扣，因為我們是每一層layer自己正規化的LN，不是跨layer正規化的BN，所以維度是 <code>x=-1</code> (表示最後一個維度，就是一筆資料) ，然後關於keepdim以下解釋</p>
<pre tabindex="0"><code># 沒有 keepdim
print(x.mean(-1))  # 結果: tensor([1.5, 3.5]), shape 為 (2,)

# 使用 keepdim=True
print(x.mean(-1, keepdim=True))  # 結果: tensor([[1.5], [3.5]]), shape 為 (2, 1)
</code></pre></li>
<li>
<p>參考<a href="https://blog.csdn.net/jq_98/article/details/123300010">這張圖</a></p>
  <img src="ln_bn.png" width=500>
</li>
</ul>
<h2 id="bn-vs-ln">BN VS. LN<a hidden class="heading-anchor" aria-hidden="true" href="#bn-vs-ln">#</a></h2>
<table>
<thead>
<tr>
<th></th>
<th>BN</th>
<th>LN</th>
</tr>
</thead>
<tbody>
<tr>
<td>size</td>
<td>batch size中的同位置不同樣本點座標準化</td>
<td>每個樣本自己內部座標準化，和batch size沒關</td>
</tr>
<tr>
<td>適合模型</td>
<td>CNN</td>
<td>RNN, LSTM, Transformer</td>
</tr>
<tr>
<td>原因</td>
<td>每層輸出的數據分布不穩定</td>
<td>序列之間沒有相關性，直接在單一序列做LN必較合理</td>
</tr>
</tbody>
</table>
<h2 id="reference">Reference<a hidden class="heading-anchor" aria-hidden="true" href="#reference">#</a></h2>
<ul>
<li><a href="https://blog.csdn.net/HUSTHY/article/details/106665809">关于batch normalization和layer normalization的理解</a></li>
<li><a href="https://paperswithcode.com/method/layer-normalization">Layer Normalization</a></li>
</ul>



        
      </article>
    </div>

    
      <div class="meta article-card">
    <div class="row">
      <span class="label">



<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M32 456a24 24 0 0024 24h400a24 24 0 0024-24V176H32zm320-244a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm-80-80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zm0 80a4 4 0 014-4h40a4 4 0 014 4v40a4 4 0 01-4 4h-40a4 4 0 01-4-4zM456 64h-55.92V32h-48v32H159.92V32h-48v32H56a23.8 23.8 0 00-24 23.77V144h448V87.77A23.8 23.8 0 00456 64z'/></svg>













Published At</span><time>2024-12-10 23:38 CST</time>
      
    </div>

    
      <div class="row">
        <span class="label">













<svg xmlns='http://www.w3.org/2000/svg' class='ionicon' viewBox='0 0 512 512'><path d='M288 16L0 304l176 176 288-288V16zm80 128a32 32 0 1132-32 32 32 0 01-32 32z'/><path d='M480 64v144L216.9 471.1 242 496l270-272V64h-32z'/></svg>



Tagged with</span>
        <ul class="tags">
        
          <li class="hashed-tag"><a href="http://localhost:1313/Hlunlun/tags/normalization">normalization</a></li>
        
          <li class="hashed-tag"><a href="http://localhost:1313/Hlunlun/tags/layer_norm">layer_norm</a></li>
        
        </ul>
      </div>
    

    

    
</div>

    

    

  </div>
</main>

    <footer id="footer">
  <div class="container has-padding is-flex">
    <ul class="links">
      
      <li>
        
        <a rel="nofollow" target="_blank" href="https://github.com/Hlunlun" title="Github">Github</a>
      </li>
      
      <li>
        <a
          rel="nofollow"
          target="_blank"
          href="https://github.com/wayjam/hugo-theme-fluency"
          title="using Hugo theme fluency">
          Theme Fluency
        </a>
      </li>
      <li>
        <a rel="nofollow" target="_blank" href="https://gohugo.io" title="Built with hugo">Built with Hugo</a>
      </li>
    </ul>
    <div class="copyright">
       &copy; 2025 Lun&#39;s
      
    </div>
  </div>
</footer>

<script>
    window.FluencyCopyIcon = '\r\n\r\n\r\n\r\n\r\n\r\n\r\n\u003csvg xmlns=\u0027http:\/\/www.w3.org\/2000\/svg\u0027 class=\u0027ionicon\u0027 viewBox=\u00270 0 512 512\u0027\u003e\u003crect x=\u0027128\u0027 y=\u0027128\u0027 width=\u0027336\u0027 height=\u0027336\u0027 rx=\u002757\u0027 ry=\u002757\u0027 stroke-linejoin=\u0027round\u0027 class=\u0027ionicon-fill-none ionicon-stroke-width\u0027\/\u003e\u003cpath d=\u0027M383.5 128l.5-24a56.16 56.16 0 00-56-56H112a64.19 64.19 0 00-64 64v216a56.16 56.16 0 0056 56h24\u0027 stroke-linecap=\u0027round\u0027 stroke-linejoin=\u0027round\u0027 class=\u0027ionicon-fill-none ionicon-stroke-width\u0027\/\u003e\u003c\/svg\u003e\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'
</script>


<script defer src="http://localhost:1313/Hlunlun/js/main.min.15ea6de828b83519cdc1bc66872563a50cd5e59b4b1cfc6f31019951922b2e78.js" integrity="sha256-Fept6Ci4NRnNwbxmhyVjpQzV5ZtLHPxvMQGZUZIrLng=" crossorigin="anonymous" async></script>


    <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
  integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X"
  crossorigin="anonymous"
/>


<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"
  integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4"
  crossorigin="anonymous"
></script>


<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
  integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa"
  crossorigin="anonymous"
  onload="renderMathInElement(document.body);"
></script>



<noscript>
<style type=text/css>#theme-selector-button{display:none}</style>
</noscript>




  </body>
</html>
