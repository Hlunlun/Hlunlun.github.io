<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss
  version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:wfw="http://wellformedweb.org/CommentAPI/"
  
    xmlns:content="http://purl.org/rss/1.0/modules/content/"
  
>
  <channel>
    <title>Transformer on Lun&#39;s</title>
    <link>http://localhost:1313/Hlunlun/tags/transformer/</link>
    <description>Recent content in Transformer on Lun&#39;s</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Feb 2025 22:08:20 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/Hlunlun/tags/transformer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Label Smoothing</title>
      <link>http://localhost:1313/Hlunlun/posts/label_smoothing/</link>
      <pubDate>Mon, 24 Feb 2025 22:08:20 +0800</pubDate>
      <guid>http://localhost:1313/Hlunlun/posts/label_smoothing/</guid>
      <description>一般是用在分類任務，可以降低 overfitting 的情況</description>
      
        <content:encoded><![CDATA[<h2 id="why">Why?</h2>
<p><img src="https://hackmd.io/_uploads/HJO3cLtc1g.png" alt="image"></p>
<p>一般是用在分類任務，假如今天是用 cifar10 來訓練模型，你有10個標籤，即 <code>label = [0,1,2,3,4,5,6,7,8,9]</code>，再輸入模型後，模型會預測這張圖片在十個標籤中的機率，可能會出現以下的狀況</p>
<ul>
<li><code>pred = [0,0,0,1,0,0,0,0,0,0]</code></li>
</ul>
<p>也就是說模型會非常肯定這張圖片一定就是第3個類別，那這樣為什麼是不好的呢?</p>
<p>因為我們不希望模型 overfitting，而overfitting的原因就是模型被答案的狀況太嚴重，造成他對很多圖片的判斷都非常自信，會造成他只把訓練即每張圖片對應的標籤都背起來但是對沒有看過的圖片(test data)就完全不知道怎麼辦</p>
<p>所以，為了增加模型的泛化能力，也就是希望模型可以更 general，而不是只能作答已經看過的問題，可以把答案做平滑的處理，如</p>
<ul>
<li><code>pred = [0.1,0,0.02,0.75,0,0.1,0,0,0.03,0]</code></li>
</ul>
<p>機率最大的依然是第三個類別，但是其他標籤還是有可能性，讓模型不要太相信一定是第三類別，這樣就可以降低 overfitting 的情況了!</p>
<h2 id="傳統-one-hot-label-的數學意義">傳統 one-hot label 的數學意義</h2>
<ol>
<li>
<p>首先可以看到計算 likelihood 的的公式，\(k\) 是第幾個類別，\(w_k\)是權重，\(x^T\)是倒數第二層的激活值，\(L\)我猜應該是類別總數假如總共有10個類別，那以下就是代表在10個類別中的機率</p>
</li>
</ol>
<p>$$p_k=\cfrac{e^{x^Tw_k}}{\sum_{l=1}^L{e^{x^Tw_l}}}$$</p>
<ol start="2">
<li>
<p>計算 Cross-Entropy 的公式如以下，我們的目標就是縮小這個loss的值，但這跟我們一般看到算loss的公式不太一樣?</p>
<p>$$H(y,p) = \sum_{k=1}^K -y_klog(p_k)$$</p>
<p>$$y_k =
\begin{cases}
1, &amp; \text{if } k \text{ is the correct class} \
0, &amp; \text{otherwise}
\end{cases}$$</p>
 <p>這邊可以簡單舉一個 cifar10 的例子，所以總類別數是 \(K=10\)， 假設 \(y_2=1\)，loss就是以下這樣</p>
<p>$$\begin{align*}
H(y, p) &amp;= \sum_{k=1}^K -y_k \log(p_k) \
&amp;= 0 \cdot \log(p_1) - 1 \cdot \log(p_2) - 0 \cdot \log(p_3) - \cdots \
&amp;= -\log(p_2) \
&amp;= \log\left(\frac{1}{p_2}\right)
\end{align*}
$$</p>
 <p>也就是說，只要 \(p_2\) 越接近 \(1\) ，\(log(\frac{1}{p_2})\) 就越接近0，就達成我們想要降低 loss 的目標!</p>
</li>
</ol>
<h2 id="label-smoothing">Label Smoothing</h2>
<ol>
<li>
<p>平滑 label 的分布，可以把這段扣畫出平滑前後的分布，其實就是把一些可能性均分給其他label，讓模型不要太果斷
:::spoiler code</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 參數設置</span>
</span></span><span class="line"><span class="cl"><span class="n">K</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># 總類別數</span>
</span></span><span class="line"><span class="cl"><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># 平滑參數</span>
</span></span><span class="line"><span class="cl"><span class="n">correct_class</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># 假設正確類別是索引 2（從 0 開始）</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 1. 未平滑的硬標籤 (one-hot)</span>
</span></span><span class="line"><span class="cl"><span class="n">hard_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">hard_label</span><span class="p">[</span><span class="n">correct_class</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 2. 平滑後的標籤</span>
</span></span><span class="line"><span class="cl"><span class="n">smoothed_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">smoothed_label</span><span class="p">[</span><span class="n">correct_class</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">K</span>  <span class="c1"># 正確類別</span>
</span></span><span class="line"><span class="cl"><span class="n">smoothed_label</span><span class="p">[</span><span class="n">hard_label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">K</span>  <span class="c1"># 其他類別</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 3. 創建數據</span>
</span></span><span class="line"><span class="cl"><span class="n">categories</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>  <span class="c1"># 類別索引 (0, 1, 2, 3, 4)</span>
</span></span><span class="line"><span class="cl"><span class="n">width</span> <span class="o">=</span> <span class="mf">0.35</span>  <span class="c1"># 柱子的寬度</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 4. 繪製柱狀圖</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">categories</span> <span class="o">-</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">hard_label</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Hard Label (No Smoothing)&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">categories</span> <span class="o">+</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">smoothed_label</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Smoothed Label (α = </span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 5. 設置圖表屬性</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Class Index&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution Before and After Label Smoothing&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">categories</span><span class="p">,</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Class </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">categories</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 6. 顯示圖表</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;label_smoothing_comparison.png&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p><img src="https://hackmd.io/_uploads/rkFGovt91l.png" alt="image"></p>
</li>
<li>
<p>數學公式，將 \(y_k\) 修改成 label smoothing 的 label 如下， \(\alpha\) 數值範圍 [0,1] 可以自己設</p>
<p>$$y_k^{LS} = y_k \cdot (1-\alpha) + \alpha/K$$</p>
<p>現在假設總共有3個類別，如果正確的label是 $k=1$，設定 $\alpha=0.1$</p>
<p>$$y_1^{LS} = 1 \cdot (1-0.1) + 0.1/3 = 0.9 + 0.0333 = 0.9333$$</p>
<p>$$y_2^{LS} = 0 \cdot (1-0.1) + 0.1/3 = 0 + 0.0333 = 0.0333$$</p>
<p>$$y_3^{LS} = 0 \cdot (1-0.1) + 0.1/3 = 0 + 0.0333 = 0.0333$$</p>
<p>正確的 $y_1$ 就會從 $1$ 降到 $0.9333$，其他就從 $0$ 上升到 $0.0333$，而不是絕對的 $0$ 和 $1$</p>
</li>
</ol>
<h2 id="implement">Implement</h2>
<p>這邊的 label smoothing 有做一點小修改，因為假設有1個padding的位置，所以均分剩下的 \(\alpha\) 的位置有 \(K-2\)</p>
<p>$$y_k^{LS} =
\begin{cases}
y_k \cdot (1-\alpha), &amp; \text{if } k \text{ is the correct class} \
\cfrac{\alpha}{K-2}, &amp; \text{otherwise}
\end{cases}$$</p>
<p>並且是用 KL loss 來算的</p>
<p>$$Loss = \sum_{i=1}^N target(i) \cdot (log(target(i)) - input(i))$$</p>
<p>就是因為這個所以要取log再丟進去算</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">LabelSmoothing</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;Implement label smoothing.&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">smoothing</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">LabelSmoothing</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span> <span class="o">=</span> <span class="n">padding_idx</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">confidence</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">smoothing</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span> <span class="o">=</span> <span class="n">smoothing</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">true_dist</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span></span><span class="line"><span class="cl">        <span class="n">true_dist</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">true_dist</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">smoothing</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">true_dist</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">confidence</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">true_dist</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">data</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">,</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">true_dist</span><span class="o">.</span><span class="n">index_fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mask</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="mf">0.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">true_dist</span> <span class="o">=</span> <span class="n">true_dist</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Variable</span><span class="p">(</span><span class="n">true_dist</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Example of label smoothing.</span>
</span></span><span class="line"><span class="cl"><span class="n">crit</span> <span class="o">=</span> <span class="n">LabelSmoothing</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">)</span>  <span class="c1"># 5 classes, padding_idx=0, smoothing=0.4</span>
</span></span><span class="line"><span class="cl"><span class="n">predict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                             <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                             <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">v</span> <span class="o">=</span> <span class="n">crit</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">predict</span><span class="o">.</span><span class="n">log</span><span class="p">()),</span> <span class="c1"># 對每個predict的值取log，因為要用 Kullback-Leibler 散度損失函數</span>
</span></span><span class="line"><span class="cl">         <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])))</span>  <span class="c1"># Targets: class 2, 1, 0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Show the target distributions expected by the system.</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set figure size for better visualization</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">crit</span><span class="o">.</span><span class="n">true_dist</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>  <span class="c1"># Use &#39;viridis&#39; colormap for better contrast</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>  <span class="c1"># Add colorbar to show probability scale</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Target Distributions After Label Smoothing (α = 0.4)&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Class Index&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Sample Index&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">crit</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Class </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">crit</span><span class="o">.</span><span class="n">size</span><span class="p">)])</span>  <span class="c1"># Label x-axis with class indices</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;label_smoothing.png&#39;</span><span class="p">))</span>  <span class="c1"># Save the plot</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Loss value:&#34;</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>  <span class="c1"># Print the loss for reference</span>
</span></span></code></pre></div><p>不同步驟填 smooth 後的 predict probability</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 取log</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[</span>   <span class="o">-</span><span class="n">inf</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6094</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3567</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3026</span><span class="p">,</span>    <span class="o">-</span><span class="n">inf</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>   <span class="o">-</span><span class="n">inf</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6094</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3567</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3026</span><span class="p">,</span>    <span class="o">-</span><span class="n">inf</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>   <span class="o">-</span><span class="n">inf</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6094</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3567</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3026</span><span class="p">,</span>    <span class="o">-</span><span class="n">inf</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 填上 α/K</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 填上 confidence</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.6000</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.6000</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="mf">0.6000</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 把 padding 的位置填 0</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.6000</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.6000</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.1333</span><span class="p">]])</span>
</span></span></code></pre></div><p>視覺化後就會看到，第2和第3個類別在不同的sample有最高機率值
<img src="https://hackmd.io/_uploads/S14weht9Jx.png" alt="image"></p>
<h2 id="kl-loss">KL Loss</h2>
<p>根據上面 label smoothing 的方式在是一個</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">crit</span> <span class="o">=</span> <span class="n">LabelSmoothing</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># 5 classes, padding_idx=0, smoothing=0.1</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 確保 x 為正數，避免數值問題</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>  <span class="c1"># 避免 x 為 0 或負數</span>
</span></span><span class="line"><span class="cl">    <span class="n">d</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">1</span>  <span class="c1"># 計算分母</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 創建概率分佈，確保總和為 1，並避免 0 值</span>
</span></span><span class="line"><span class="cl">    <span class="n">predict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">x</span> <span class="o">/</span> <span class="n">d</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">d</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">d</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">d</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">    <span class="n">predict</span> <span class="o">=</span> <span class="n">predict</span> <span class="o">/</span> <span class="n">predict</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 正規化概率</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 計算 KL 損失</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">crit</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">predict</span><span class="o">.</span><span class="n">log</span><span class="p">()),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 繪製損失曲線</span>
</span></span><span class="line"><span class="cl"><span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>  <span class="c1"># x 從 1 到 99</span>
</span></span><span class="line"><span class="cl"><span class="n">y_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_values</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;KL Loss with Label Smoothing (α = 0.1)&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;KL Loss vs. x with Label Smoothing&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;kl_loss_curve.png&#39;</span><span class="p">))</span>  <span class="c1"># 儲存損失曲線圖表</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Loss curve generated and saved as &#39;kl_loss_curve.png&#39;&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>這裡就要說 label smoothing 的缺點了，如果 (\alpha) 太大就會變成 underfit 的問題囉，loss 都完全沒要下降
<img src="https://hackmd.io/_uploads/HJRawnFcyx.png" alt="image"></p>
<h2 id="example">Example</h2>
<p>假設 <code>size=5</code>（詞彙表大小為 5），<code>smoothing=0.1</code>，<code>padding_idx=0</code>：</p>
<ul>
<li>原始 one-hot 標籤（目標為類別 2）：<code>[0, 0, 1, 0, 0]</code></li>
<li>平滑後標籤：
<ul>
<li><code>confidence = 1 - 0.1 = 0.9</code></li>
<li><code>smoothing / (size - 2) = 0.1 / (5 - 2) = 0.0333</code></li>
<li>平滑分佈：<code>[0, 0.0333, 0.9, 0.0333, 0.0333]</code></li>
<li>如果目標是 <code>padding_idx=0</code>，則整行設為 0
這種分佈告訴模型：雖然類別 2 是正確答案，但其他類別也有微小的可能性，從而避免模型過於偏向單一預測</li>
</ul>
</li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://blog.csdn.net/ytusdc/article/details/128503206">标签平滑（Label Smoothing）详解</a></li>
<li><a href="https://paperswithcode.com/method/label-smoothing">Label Smoothing</a></li>
<li><a href="https://arxiv.org/pdf/1906.02629">When Does Label Smoothing Help?</a>
<blockquote>
<p>甚至這篇就有用到蒸餾!</p>
</blockquote>
</li>
</ul>
]]></content:encoded>
      
    </item>
  </channel>
</rss>
